{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 26 15:18:46 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    25W / 250W |     11MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user-home/1002/DSX_Projects/kmeans2/jupyter\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8279760\r\n",
      "-rw-------. 1 root root 8478473728 Jun 26  2018 gdelt-skgm-300-16-8_v2.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lL /user-home/1002/DSX_Projects/kmeans2/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "# Want TensorFlow to not allocate memory for \"all of the GPUs\"\n",
    "import os\n",
    "\n",
    "def batched_reduce(total_sz, points, centroids, batch_n):\n",
    "    \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "    \n",
    "    all_distances = None\n",
    "    batch_sz = int(math.ceil(float(total_sz) / batch_n))\n",
    "    #print(\"Total size: %d, batch size: %d\" % (total_sz, batch_sz))\n",
    "\n",
    "    # The resulting shape is [1, pd_1.shape[0], pd_1.shape[1]]\n",
    "    points_expanded = tf.expand_dims(points, 0)\n",
    "\n",
    "    # The resulting shape is [clusters_n, 1, pd_1.shape[1]]\n",
    "    centroids_expanded = tf.expand_dims(centroids.initialized_value(), 1)\n",
    "\n",
    "    for x in range(batch_n):\n",
    "        slice_start = x * batch_sz\n",
    "        slice_end = slice_start + batch_sz\n",
    "        #print(\"Batch: %d, slice start: %d, slice end: %d\" % (x, slice_start, slice_end))\n",
    "        if (slice_end < total_sz):\n",
    "            # Working with points_expanded with shape [1, pd_1.shape[0], pd_1.shape[1]]\n",
    "            points_exp = tf.slice(points_expanded, [0, slice_start, 0], [1, batch_sz, centroids_expanded.shape[2]])        \n",
    "        else:\n",
    "            points_exp = tf.slice(points_expanded, [0, slice_start, 0], [1, total_sz-slice_start, centroids_expanded.shape[2]])\n",
    "\n",
    "        device_name2= \"/gpu:0\"\n",
    "        #device_name2= \"/cpu:0\"\n",
    "        with tf.device(device_name2):                \n",
    "            dist = tf.reduce_sum(tf.square(tf.subtract(points_exp, centroids_expanded)), 2)          \n",
    "\n",
    "        if (all_distances == None): \n",
    "            all_distances = dist\n",
    "        else:    \n",
    "            all_distances = tf.concat([all_distances, dist], 1)\n",
    "        #print(all_distances.shape)\n",
    "\n",
    "        if (slice_end >= total_sz):\n",
    "            break\n",
    "    \n",
    "    return all_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "points_n = 2000\n",
    "clusters_n = 5\n",
    "iteration_n = 100\n",
    "batch_n = 15\n",
    "\n",
    "device_name = \"/gpu:0\"\n",
    "#device_name = \"/cpu:0\"\n",
    "with tf.device(device_name):     \n",
    "    #scenario 1: with generated points\n",
    "    #points = tf.constant(np.random.uniform(0, 10, (points_n, 2)))\n",
    "    #centroids = tf.Variable(tf.slice(tf.random_shuffle(points), [0, 0], [clusters_n, -1]))\n",
    "\n",
    "    #scenario 2: with 500 KB data set    \n",
    "    #pd_1 = pd.read_csv('/user-home/1002/DSX_Projects/test2/Finance-50-16-8_v4.csv')\n",
    "    #points = tf.constant(pd_1.as_matrix())    \n",
    "       \n",
    "    #scenario 4: with 1 GB data set\n",
    "    pd_1 = pd.read_csv('/user-home/1002/DSX_Projects/kmeans2/datasets/gdelt1gb.csv', header=None, index_col=0)\n",
    "    \n",
    "    #scenario 5: with 15GB data set (CPU only)    \n",
    "    #pd_1 = pd.read_csv('/user-home/1002/DSX_Projects/kmeans2/datasets/gdelt-skgm-300-16-8_v2.csv', header=None, index_col=0)\n",
    "          \n",
    "    df_1 = pd_1.as_matrix()\n",
    "    df_ph = tf.placeholder(tf.float64, shape=pd_1.shape)\n",
    "    points = tf.get_variable(\"points\", shape=pd_1.shape, dtype=tf.float64, initializer=tf.zeros_initializer())\n",
    "    centroids = tf.get_variable(\"centroids\", shape=[clusters_n, pd_1.shape[1]], dtype=tf.float64, initializer=tf.zeros_initializer())\n",
    "               \n",
    "    # The resulting shape of tf.subtract is [clusters_n, pd_1.shape[0], pd_1.shape[1]]\n",
    "    # The resulting shape of tf.square keeps the input shape\n",
    "    # From tf.reduce_sum with reduction_indices=2, the result shape becomes [clusters_n, pd_1.shape[0]]        \n",
    "    points_expanded = tf.expand_dims(points, 0)        \n",
    "    centroids_expanded = tf.expand_dims(centroids.initialized_value(), 1)\n",
    "    distances = tf.reduce_sum(tf.square(tf.subtract(points_expanded, centroids_expanded)), 2)\n",
    "    #distances = batched_reduce(pd_1.shape[0], points, centroids, batch_n)\n",
    "    #print(distances.shape)\n",
    "\n",
    "    #device3_name = \"/cpu:0\"\n",
    "    #device3_name = \"/gpu:0\"\n",
    "    #with tf.device(device3_name):    \n",
    "    assignments = tf.argmin(distances, 0)\n",
    "    assignments = tf.to_int32(assignments)\n",
    "\n",
    "    partitions = tf.dynamic_partition(points, assignments, clusters_n)\n",
    "    new_centroids = tf.concat([tf.expand_dims(tf.reduce_mean(partition, 0), 0) for partition in partitions], 0)\n",
    "\n",
    "    update_centroids = tf.assign(centroids, new_centroids)\n",
    "\n",
    "    init = tf.global_variables_initializer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Want TensorFlow to not allocate \"all of the memory\" for the GPUs visible to it\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "def run_kmeans():\n",
    "    startTime = datetime.now()    \n",
    "\n",
    "    with tf.Session(config=config) as sess:  \n",
    "\n",
    "        sess.run(init)\n",
    "        sess.run(points.assign(df_ph), feed_dict={df_ph: df_1})\n",
    "        sess.run(centroids.assign(tf.slice(tf.random_shuffle(points), [0, 0], [clusters_n, -1])))\n",
    "\n",
    "        startTime2 = datetime.now()   \n",
    "\n",
    "        # for step in xrange(iteration_n):\n",
    "        for step in range(iteration_n):    \n",
    "            [_, centroid_values, points_values, assignment_values] = sess.run([update_centroids, centroids, points, assignments])\n",
    "        print(\"Execution time taken:\", datetime.now() - startTime2)   \n",
    "        #print \"centroids\" + \"\\n\", centroid_values\n",
    "\n",
    "    print(\"Total time taken:\", datetime.now() - startTime)  \n",
    "\n",
    "    #plt.scatter(points_values[:, 0], points_values[:, 1], c=assignment_values, s=50, alpha=0.5)\n",
    "    #plt.plot(centroid_values[:, 0], centroid_values[:, 1], 'kx', markersize=15)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# execute code with extra process so that at the end of the process the memory is released\n",
    "p = multiprocessing.Process(target=run_kmeans)\n",
    "p.start()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with DSX Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
